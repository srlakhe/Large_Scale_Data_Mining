{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from os import listdir\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime, time\n",
    "import pytz\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
    "from math import sqrt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['df_train_part1e_tweets_#gohawks.csv', 'df_train_part1e_tweets_#gopatriots.csv', 'df_train_part1e_tweets_#nfl.csv', 'df_train_part1e_tweets_#patriots.csv', 'df_train_part1e_tweets_#sb49.csv', 'df_train_part1e_tweets_#superbowl.csv']\n",
      "               time_of_tweet  num_of_tweets  num_retweets  sum_followers  \\\n",
      "0  2014-12-28 14:14:35-08:00            1.0           5.0         1752.0   \n",
      "1  2014-12-29 06:40:08-08:00            1.0           2.0          258.0   \n",
      "2  2014-12-29 07:27:13-08:00            1.0           7.0          199.0   \n",
      "3  2014-12-29 11:27:20-08:00            1.0           5.0           22.0   \n",
      "4  2014-12-29 12:10:38-08:00            1.0           2.0           22.0   \n",
      "\n",
      "   max_followers  sum_fav_count  sum_verified  sum_status  sum_friends  \\\n",
      "0         1752.0            1.0           0.0     12477.0       2025.0   \n",
      "1          258.0            0.0           0.0       156.0         29.0   \n",
      "2          199.0            0.0           0.0       552.0        190.0   \n",
      "3           22.0            0.0           0.0      3897.0       1455.0   \n",
      "4           22.0            0.0           0.0     82505.0         17.0   \n",
      "\n",
      "   sum_ranking_score  sum_impressions  sum_momentum  \n",
      "0                4.0           1754.0           1.0  \n",
      "1                3.0            162.0           0.0  \n",
      "2                4.0            183.0           1.0  \n",
      "3                3.0              5.0           1.0  \n",
      "4                3.0              5.0           0.0  \n",
      "Reading CSV 1 done\n",
      "(188136, 12)\n",
      "(214368, 12)\n",
      "(473392, 12)\n",
      "(963105, 12)\n",
      "(1790056, 12)\n",
      "(3138823, 12)\n"
     ]
    }
   ],
   "source": [
    "csv_files = os.listdir(\"D:/Git/Data_for_project5/Part1E_data_train/\")\n",
    "print(csv_files)\n",
    "features = [\"num_of_tweets\",\"num_of_retweets\",\"Sum of followers\",\" max of followers\",\"hour\",\"count of favorites\",\"sum of verified\",\"sum of status\",\"sum of friends\",\"sum of ranking scores\",\"sum of impressions\",\"sum of momentum\"]\n",
    "\n",
    "for csv_file in csv_files:\n",
    "    #print(\"Doing OLS for \" + csv_file[10:-4])\n",
    "    #print(\"**************************************************************\")\n",
    "    df = pd.read_csv(\"D:/Git/Data_for_project5/Part1E_data_train/\" + csv_file, index_col = 0)\n",
    "    print(df.head())\n",
    "    \n",
    "    print(\"Reading CSV 1 done\")\n",
    "    final_df = df.copy()\n",
    "    print(final_df.shape)\n",
    "    break\n",
    "for i in range(1,len(csv_files)):\n",
    "    df = pd.read_csv(\"D:/Git/Data_for_project5/Part1E_data_train/\" + csv_files[i],index_col = 0)\n",
    "    final_df = pd.concat([final_df,df],axis = 0)\n",
    "    print(final_df.shape)\n",
    "    \n",
    "df[\"time_of_tweet\"] = [i[:-6] for i in df[\"time_of_tweet\"]]\n",
    "df['time_of_tweet'] = pd.to_datetime(df['time_of_tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train(df):\n",
    "    hourly_df = df.groupby(pd.TimeGrouper(key = 'time_of_tweet',freq = '60Min'))\n",
    "    X_train = np.zeros((len(hourly_df),12))\n",
    "    Y_train = np.zeros((len(hourly_df)))\n",
    "    for i,(hour,grp) in enumerate(hourly_df):\n",
    "        X_train[i,0] = grp.num_of_tweets.sum()\n",
    "        X_train[i,1] = grp.num_retweets.sum()\n",
    "        X_train[i,2] = grp.sum_followers.sum()\n",
    "        X_train[i,3] = grp.max_followers.max()\n",
    "        X_train[i,4] = hour.hour\n",
    "        X_train[i,5] = grp.sum_fav_count.sum()\n",
    "        X_train[i,6] = grp.sum_verified.sum()\n",
    "        X_train[i,7] = grp.sum_status.sum()\n",
    "        X_train[i,8] = grp.sum_friends.sum()\n",
    "        X_train[i,9] = grp.sum_ranking_score.sum()\n",
    "        X_train[i,10] = grp.sum_impressions.sum()\n",
    "        X_train[i,11] = grp.sum_momentum.sum()\n",
    "\n",
    "        Y_train[i] = grp.num_of_tweets.sum()\n",
    "    Y_train = Y_train[1:]\n",
    "    X_train = X_train[:-1]\n",
    "    X_train = np.nan_to_num(X_train)\n",
    "    return X_train,Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_test(df):\n",
    "    hourly_df = df.groupby(pd.TimeGrouper(key = 'time_of_tweet',freq = '60Min'))\n",
    "    X_train = np.zeros((len(hourly_df),12))\n",
    "    Y_train = np.zeros((len(hourly_df)))\n",
    "    for i,(hour,grp) in enumerate(hourly_df):\n",
    "        X_train[i,0] = grp.num_of_tweets.sum()\n",
    "        X_train[i,1] = grp.num_retweets.sum()\n",
    "        X_train[i,2] = grp.sum_followers.sum()\n",
    "        X_train[i,3] = grp.max_followers.max()\n",
    "        X_train[i,4] = hour.hour\n",
    "        X_train[i,5] = grp.sum_fav_count.sum()\n",
    "        X_train[i,6] = grp.sum_verified.sum()\n",
    "        X_train[i,7] = grp.sum_status.sum()\n",
    "        X_train[i,8] = grp.sum_friends.sum()\n",
    "        X_train[i,9] = grp.sum_ranking_score.sum()\n",
    "        X_train[i,10] = grp.sum_impressions.sum()\n",
    "        X_train[i,11] = grp.sum_momentum.sum()\n",
    "\n",
    "        Y_train[i] = grp.num_of_tweets.sum()\n",
    "    X_train = np.nan_to_num(X_train)\n",
    "    return X_train,Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "963\n",
      "(215075, 12)\n",
      "(1027317, 12)\n",
      "(106375, 12)\n"
     ]
    }
   ],
   "source": [
    "X,Y = make_train(df)\n",
    "print(len(X))\n",
    "\n",
    "df1 = df[df.time_of_tweet < datetime.datetime(2015,2,1,8,0,0)]\n",
    "print(df1.shape)\n",
    "df2 = df[(df.time_of_tweet >= datetime.datetime(2015,2,1,8,0,0)) & (df.time_of_tweet <= datetime.datetime(2015,2,1,20,0,0))]\n",
    "print(df2.shape)\n",
    "df3 = df[df.time_of_tweet > datetime.datetime(2015,2,1,20,0,0)]\n",
    "print(df3.shape)\n",
    "\n",
    "X1,Y1 = make_train(df1)\n",
    "X2,Y2 = make_train(df2)\n",
    "X3,Y3 = make_train(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "816\n",
      "816\n",
      "11\n",
      "11\n",
      "134\n",
      "134\n",
      "963\n",
      "963\n"
     ]
    }
   ],
   "source": [
    "print(len(X1))\n",
    "print(len(Y1))\n",
    "\n",
    "print(len(X2))\n",
    "print(len(Y2))\n",
    "\n",
    "print(len(X3))\n",
    "print(len(Y3))\n",
    "\n",
    "print(len(X))\n",
    "print(len(Y))\n",
    "\n",
    "X1_new = []\n",
    "Y1_new = []\n",
    "\n",
    "for i in range(0,len(X1)):\n",
    "    if i + 5 >= len(X1):\n",
    "        break\n",
    "    temp1 = X1[i:i+5,].copy()\n",
    "    temp1 = temp1.ravel()\n",
    "    #print(temp1.shape)\n",
    "    X1_new.append(temp1)\n",
    "    Y1_new.append(X1[i+5][0])\n",
    "X2_new = []\n",
    "Y2_new = []\n",
    "\n",
    "for i in range(0,len(X2)):\n",
    "    if i + 5 >= len(X2):\n",
    "        break\n",
    "    temp2 = X2[i:i+5,].copy()\n",
    "    temp2 = temp2.ravel()\n",
    "    \n",
    "    X2_new.append(temp2)\n",
    "    Y2_new.append(X2[i+5][0])\n",
    "X3_new = []\n",
    "Y3_new = []\n",
    "\n",
    "for i in range(0,len(X3)):\n",
    "    if i + 5 >= len(X3):\n",
    "        break\n",
    "    temp3 = X3[i:i+5,].copy()\n",
    "    temp3 = temp3.ravel()\n",
    "    X3_new.append(temp3)\n",
    "    Y3_new.append(X3[i+5][0])\n",
    "\n",
    "X_new = []\n",
    "Y_new = []\n",
    "\n",
    "for i in range(0,len(X)):\n",
    "    if i + 5 >= len(X):\n",
    "        break\n",
    "    temp = X[i:i+5,].copy()\n",
    "    temp = temp.ravel()\n",
    "    X_new.append(temp)\n",
    "    Y_new.append(X[i+5][0])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "811\n",
      "60\n",
      "811\n",
      "6\n",
      "60\n",
      "6\n",
      "129\n",
      "60\n",
      "129\n",
      "958\n",
      "60\n",
      "958\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=5,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_full = RandomForestRegressor(n_estimators = 20, max_depth = 5)\n",
    "model1 = RandomForestRegressor(n_estimators = 20,max_depth = 5)\n",
    "model2 = RandomForestRegressor(n_estimators = 20,max_depth = 5)\n",
    "model3 = RandomForestRegressor(n_estimators = 20,max_depth = 5)\n",
    "#print(X1_new[0:5])\n",
    "X1_train = X1_new.copy()\n",
    "X2_train = X2_new.copy()\n",
    "X3_train = X3_new.copy()\n",
    "\n",
    "Y1_train = Y1_new.copy()\n",
    "Y2_train = Y2_new.copy()\n",
    "Y3_train = Y3_new.copy()\n",
    "\n",
    "X_train = X_new.copy()\n",
    "#print(X_train[0:5])\n",
    "Y_train = Y_new.copy()\n",
    "print(len(X1_train))\n",
    "print(len(X1_train[0]))\n",
    "print(len(Y1_train))\n",
    "print(len(X2_train))\n",
    "print(len(X2_train[0]))\n",
    "print(len(Y2_train))\n",
    "print(len(X3_train))\n",
    "print(len(X3_train[0]))\n",
    "print(len(Y3_train))\n",
    "print(len(X_train))\n",
    "print(len(X_train[0]))\n",
    "print(len(Y_train))\n",
    "model1.fit(np.asarray(X1_train),np.asarray(Y1_train))\n",
    "model2.fit(np.asarray(X2_train), np.asarray(Y2_train))\n",
    "model3.fit(np.asarray(X3_train), np.asarray(Y3_train))\n",
    "model_full.fit(np.asarray(X_train), np.asarray(Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['df_part1e_sample10_period3.csv', 'df_part1e_sample1_period1.csv', 'df_part1e_sample2_period2.csv', 'df_part1e_sample3_period3.csv', 'df_part1e_sample4_period1.csv', 'df_part1e_sample5_period1.csv', 'df_part1e_sample6_period2.csv', 'df_part1e_sample7_period3.csv', 'df_part1e_sample8_period1.csv', 'df_part1e_sample9_period2.csv']\n",
      "sample10\n",
      "Interval = 3\n",
      "(6, 12)\n",
      "(2, 60)\n",
      "[19.91295455 20.59856061]\n",
      "[19.58369129 23.96674623]\n",
      "[62. 54. 68. 62. 58. 61.]\n",
      "sample1_\n",
      "Interval = 1\n",
      "(6, 12)\n",
      "(2, 60)\n",
      "[182.66158937 204.1584097 ]\n",
      "[140.27998125 186.74507106]\n",
      "[137.  82.  68.  94. 171. 178.]\n",
      "sample2_\n",
      "Interval = 2\n",
      "(6, 12)\n",
      "(2, 60)\n",
      "[111839.6  139914.85]\n",
      "[125789.87857143 137591.42857143]\n",
      "[ 7591.  9361. 10374. 20066. 81958. 82923.]\n",
      "sample3_\n",
      "Interval = 3\n",
      "(6, 12)\n",
      "(2, 60)\n",
      "[698.67832431 558.6489206 ]\n",
      "[510.11058076 448.42928797]\n",
      "[441. 550. 610. 888. 616. 523.]\n",
      "sample4_\n",
      "Interval = 1\n",
      "(6, 12)\n",
      "(2, 60)\n",
      "[318.65617763 251.92456719]\n",
      "[323.78925337 283.08022961]\n",
      "[419. 257. 236. 266. 267. 201.]\n",
      "sample5_\n",
      "Interval = 1\n",
      "(6, 12)\n",
      "(2, 60)\n",
      "[290.96883161 307.60359749]\n",
      "[323.78925337 309.87361544]\n",
      "[342. 508. 353. 362. 281. 213.]\n",
      "sample6_\n",
      "Interval = 2\n",
      "(6, 12)\n",
      "(2, 60)\n",
      "[ 86063.65 116521.4 ]\n",
      "[108767.09464286  98572.82857143]\n",
      "[  979. 12931. 60619. 52699. 41019. 37307.]\n",
      "sample7_\n",
      "Interval = 3\n",
      "(6, 12)\n",
      "(2, 60)\n",
      "[ 24.46969503 142.97301726]\n",
      "[23.96674623 81.57467395]\n",
      "[125. 102.  66.  60.  55. 120.]\n",
      "sample8_\n",
      "Interval = 1\n",
      "(5, 12)\n",
      "(1, 60)\n",
      "[12.38005092]\n",
      "[19.58369129]\n",
      "[49. 72. 56. 41. 11.]\n",
      "sample9_\n",
      "Interval = 2\n",
      "(6, 12)\n",
      "(2, 60)\n",
      "[66928.45 76089.4 ]\n",
      "[4584.25254641 4308.73781016]\n",
      "[1729. 1734. 1619. 1582. 1857. 2790.]\n"
     ]
    }
   ],
   "source": [
    "csv_files = os.listdir(\"D:/Git/Data_for_project5/Part1E_data_test/\")\n",
    "print(csv_files)\n",
    "features = [\"num_of_tweets\",\"num_of_retweets\",\"Sum of followers\",\" max of followers\",\"hour\",\"count of favorites\",\"sum of verified\",\"sum of status\",\"sum of friends\",\"sum of ranking scores\",\"sum of impressions\",\"sum of momentum\"]\n",
    "\n",
    "for csv_file in csv_files:\n",
    "    #print(\"Doing OLS for \" + csv_file[10:-4])\n",
    "    #print(\"**************************************************************\")\n",
    "    df = pd.read_csv(\"D:/Git/Data_for_project5/Part1E_data_test/\" + csv_file, index_col = 0)\n",
    "    df[\"time_of_tweet\"] = [i[:-6] for i in df[\"time_of_tweet\"]]\n",
    "    df['time_of_tweet'] = pd.to_datetime(df['time_of_tweet'])\n",
    "    \n",
    "    print(csv_file[10:18])\n",
    "    interval = int(csv_file[-5])\n",
    "    print(\"Interval = \" + str(interval))\n",
    "    if interval == 1:\n",
    "        X_test_1, Y_test_1 = make_test(df)\n",
    "        #print(X_test_1[-5:])\n",
    "        print(X_test_1.shape)\n",
    "        X_test_new_1 = []\n",
    "        #Y_new = []\n",
    "\n",
    "        for i in range(0,len(X_test_1)):\n",
    "            if i + 4 >= len(X_test_1):\n",
    "                break\n",
    "            temp1 = X_test_1[i:i+5,].copy()\n",
    "            temp1 = temp1.ravel()\n",
    "\n",
    "            X_test_new_1.append(temp1)\n",
    "            #Y_new.append(X[i+5][0])\n",
    "        X_test_new_1 = np.asarray(X_test_new_1)\n",
    "        print(X_test_new_1.shape)\n",
    "        preds = model1.predict(X_test_new_1)\n",
    "        print(preds)\n",
    "        preds = model_full.predict(X_test_new_1)\n",
    "        print(preds)\n",
    "        print(Y_test_1)\n",
    "        #plt.scatter(preds,Y_new)\n",
    "    elif interval == 2:\n",
    "        X_test_2,Y_test_2 = make_test(df)\n",
    "        print(X_test_2.shape)\n",
    "        X_test_new_2 = []\n",
    "        #Y_new = []\n",
    "\n",
    "        for i in range(0,len(X_test_2)):\n",
    "            if i + 4 >= len(X_test_2):\n",
    "                break\n",
    "            temp2 = X_test_2[i:i+5,].copy()\n",
    "            temp2 = temp2.ravel()\n",
    "\n",
    "            X_test_new_2.append(temp2)\n",
    "            #Y_new.append(X[i+5][0])\n",
    "        X_test_new_2 = np.asarray(X_test_new_2)\n",
    "        print(X_test_new_2.shape)\n",
    "        preds = model2.predict(X_test_new_2)\n",
    "        print(preds)\n",
    "        preds = model_full.predict(X_test_new_2)\n",
    "        print(preds)\n",
    "        print(Y_test_2)\n",
    "        #plt.scatter(preds,Y_new)\n",
    "    elif interval == 3:\n",
    "        X_test_3, Y_test_3 = make_test(df)\n",
    "        print(X_test_3.shape)\n",
    "        X_test_new_3 = []\n",
    "        #Y_new = []\n",
    "        \n",
    "\n",
    "        for i in range(0,len(X_test_3)):\n",
    "            if i + 4 >= len(X_test_3):\n",
    "                break\n",
    "            temp3 = X_test_3[i:i+5,].copy()\n",
    "            temp3 = temp3.ravel()\n",
    "\n",
    "            X_test_new_3.append(temp3)\n",
    "            #Y_new.append(X[i+5][0])\n",
    "        X_test_new_3 = np.asarray(X_test_new_3)\n",
    "        print(X_test_new_3.shape)\n",
    "        preds = model3.predict(X_test_new_3)\n",
    "        print(preds)\n",
    "        preds = model_full.predict(X_test_new_3)\n",
    "        print(preds)\n",
    "        print(Y_test_3)\n",
    "        #plt.scatter(preds,Y_new)\n",
    "        \n",
    "    #print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
